#!/usr/bin/env python3
"""
å°†OpenWBCæ ¼å¼çš„æ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼

ç”¨æ³•:
python convert_to_lerobot.py \
    --input_dir /Users/jimmyp/Documents/project/OpenWBC/pick_cola \
    --output_dir ./lerobot_dataset \
    --dataset_name "pick_cola" \
    --robot_type "g1" \
    --fps 30
"""

import argparse
import json
import os
from pathlib import Path
import shutil
import tempfile
from typing import Dict, List, Any
import numpy as np
import pandas as pd
from PIL import Image
import cv2
from tqdm import tqdm
import ast

def parse_json_data(json_file: Path) -> Dict[str, Any]:
    """è§£ædata.jsonæ–‡ä»¶"""
    print(f"è§£ææ–‡ä»¶: {json_file}")
    with open(json_file, 'r') as f:
        data = json.load(f)
    return data

def extract_state_vector(states_dict):
    """ä»stateså­—å…¸ä¸­æå–40ç»´çŠ¶æ€å‘é‡"""
    # æŒ‰é¡ºåºæå–: left_arm(7) + right_arm(7) + left_hand(7) + right_hand(7) + left_leg(6) + right_leg(6)
    state_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in states_dict and 'qpos' in states_dict['left_arm']:
        state_parts.extend(states_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)  
    if 'right_arm' in states_dict and 'qpos' in states_dict['right_arm']:
        state_parts.extend(states_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in states_dict and 'qpos' in states_dict['left_hand']:
        state_parts.extend(states_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in states_dict and 'qpos' in states_dict['right_hand']:
        state_parts.extend(states_dict['right_hand']['qpos'])
    
    # left_leg qpos (6ç»´)
    if 'left_leg' in states_dict and 'qpos' in states_dict['left_leg']:
        state_parts.extend(states_dict['left_leg']['qpos'])
    
    # right_leg qpos (6ç»´)
    if 'right_leg' in states_dict and 'qpos' in states_dict['right_leg']:
        state_parts.extend(states_dict['right_leg']['qpos'])
    
    return np.array(state_parts, dtype=np.float64)

def extract_action_vector(actions_dict):
    """ä»actionså­—å…¸ä¸­æå–32ç»´åŠ¨ä½œå‘é‡"""
    # æŒ‰é¡ºåºæå–: left_arm(7) + right_arm(7) + left_hand(7) + right_hand(7) + controller_command(4)
    action_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in actions_dict and 'qpos' in actions_dict['left_arm']:
        action_parts.extend(actions_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)
    if 'right_arm' in actions_dict and 'qpos' in actions_dict['right_arm']:
        action_parts.extend(actions_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in actions_dict and 'qpos' in actions_dict['left_hand']:
        action_parts.extend(actions_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in actions_dict and 'qpos' in actions_dict['right_hand']:
        action_parts.extend(actions_dict['right_hand']['qpos'])
    
    # controller command (4ç»´) - ä½¿ç”¨left_legçš„qpos (å› ä¸ºleft_legå’Œright_legæ˜¯ç›¸åŒçš„é¥æ§å™¨command)
    if 'left_leg' in actions_dict and 'qpos' in actions_dict['left_leg']:
        # è¿™é‡Œqposå¯èƒ½æ˜¯åµŒå¥—åˆ—è¡¨ [[x,y,yaw,z]]ï¼Œéœ€è¦å±•å¹³
        controller_cmd = actions_dict['left_leg']['qpos']
        if isinstance(controller_cmd[0], list):
            controller_cmd = controller_cmd[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        action_parts.extend(controller_cmd)
    
    return np.array(action_parts, dtype=np.float64)

def convert_episode(input_episode_dir: Path, episode_idx: int, output_dir: Path, fps: float, task_map: Dict[str, int] = None) -> Dict[str, Any]:
    """è½¬æ¢å•ä¸ªepisode"""
    print(f"è½¬æ¢episode {episode_idx}...")
    
    # è¯»å–JSONæ•°æ®
    json_path = input_episode_dir / "data.json"
    if not json_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°data.jsonæ–‡ä»¶: {json_path}")
    
    episode_data = parse_json_data(json_path)
    
    # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
    if "data" not in episode_data:
        raise ValueError(f"Episode {episode_idx}: data.jsonç¼ºå°‘dataå­—æ®µ")
    
    data_frames = episode_data["data"]
    task_info = episode_data.get("text", {})
    
    # åˆ›å»ºepisodeæ•°æ®
    episode_length = len(data_frames)
    frames_data = []
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    colors_dir = input_episode_dir / "colors"
    if colors_dir.exists():
        color_files = sorted([f for f in colors_dir.glob("*.jpg") if f.is_file()])
    else:
        color_files = []
    
    for frame_idx, frame_data in enumerate(data_frames):
        # ç¡®å®štask_index
        task_description = task_info.get("goal", "default_task") if task_info else "default_task"
        current_task_index = task_map.get(task_description, 0) if task_map else 0
        
        processed_frame = {
            "episode_index": episode_idx,
            "frame_index": frame_idx,
            "timestamp": frame_idx / fps,  # æ—¶é—´æˆ³å¿…é¡»ä¸è§†é¢‘å¸§ç²¾ç¡®å¯¹åº”ï¼šç¬¬frame_idxå¸§ = frame_idx/fpsç§’
            "task_index": current_task_index,
        }
        
        # æ·»åŠ statesæ•°æ®ä½œä¸ºobservation.state
        if "states" in frame_data and frame_data["states"]:
            # æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼Œè¿™é‡Œå‡è®¾statesæ˜¯ä¸ªå­—å…¸æˆ–åˆ—è¡¨
            states = frame_data["states"]
            if isinstance(states, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–left_armçš„æ•°æ®
                if "left_arm" in states:
                    processed_frame["observation.state"] = extract_state_vector(states)
                else:
                    # è½¬æ¢ä¸ºåˆ—è¡¨
                    processed_frame["observation.state"] = extract_state_vector(states)
            else:
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨
                processed_frame["observation.state"] = extract_state_vector(states)
        
        # æ·»åŠ å›¾åƒè·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if frame_idx < len(color_files):
            # è¿™é‡Œæˆ‘ä»¬å…ˆè®°å½•åŸå§‹å›¾åƒè·¯å¾„ï¼Œç¨åä¼šè½¬æ¢ä¸ºè§†é¢‘
            processed_frame["image_path"] = str(color_files[frame_idx])
        
        # æ·»åŠ actionæ•°æ®
        if "actions" in frame_data and frame_data["actions"]:
            actions = frame_data["actions"]
            if isinstance(actions, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–left_armçš„æ•°æ®
                if "left_arm" in actions:
                    processed_frame["action"] = extract_action_vector(actions)
                else:
                    # è½¬æ¢ä¸ºåˆ—è¡¨
                    processed_frame["action"] = extract_action_vector(actions)
            else:
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨
                processed_frame["action"] = extract_action_vector(actions)
        
        # æ·»åŠ episodeç»“æŸæ ‡å¿—å’Œnext.reward
        processed_frame["next.done"] = frame_idx == episode_length - 1
        processed_frame["next.reward"] = 0.0  # æ·»åŠ é»˜è®¤reward
        
        # ä¸ºäº†å…¼å®¹GR00Tæ ¼å¼ï¼Œæ·»åŠ ä»»åŠ¡æè¿°ç›¸å…³å­—æ®µ
        if task_info and "goal" in task_info:
            # æ ¹æ®å®˜æ–¹æ ¼å¼ï¼Œtask_descriptionåº”è¯¥æ˜¯task_indexï¼ˆint64ï¼‰
            processed_frame["annotation.human.action.task_description"] = current_task_index
        
        # æ·»åŠ annotation validityå­—æ®µï¼Œè¡¨ç¤ºäººå·¥æ ‡æ³¨çš„æœ‰æ•ˆæ€§
        processed_frame["annotation.human.validity"] = 1
        
        frames_data.append(processed_frame)
    
    return {
        "frames": frames_data,
        "length": episode_length,
        "episode_index": episode_idx,
        "task_info": task_info
    }

def create_videos_from_images(input_dir: Path, output_videos_dir: Path, episode_data: List[Dict], fps: float, code_type: str='h264'):
    """ä»å›¾åƒåºåˆ—åˆ›å»ºè§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å›¾åƒå°ºå¯¸"""
    print("åˆ›å»ºè§†é¢‘æ–‡ä»¶...")
    
    image_shape = None  # ç”¨äºå­˜å‚¨å›¾åƒå°ºå¯¸ä¿¡æ¯
    
    # ä¸ºæ¯ä¸ªepisodeåˆ›å»ºè§†é¢‘
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        episode_dir = input_dir / f"episode_{episode_idx+1:04d}"  # episodeç›®å½•ä»1å¼€å§‹ç¼–å·
        colors_dir = episode_dir / "colors"
        
        if not colors_dir.exists():
            print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰colorsç›®å½•ï¼Œè·³è¿‡è§†é¢‘åˆ›å»º")
            continue
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = sorted([f for f in colors_dir.glob("*.jpg") if f.is_file()])
        if not image_files:
            print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰å›¾åƒæ–‡ä»¶ï¼Œè·³è¿‡è§†é¢‘åˆ›å»º")
            continue
        
        # ç¡®å®šè§†é¢‘è¾“å‡ºè·¯å¾„
        video_output_dir = output_videos_dir / "chunk-000" / "observation.images.ego_view"
        video_output_dir.mkdir(parents=True, exist_ok=True)
        video_path = video_output_dir / f"episode_{episode_idx:06d}.mp4"
        
        # è¯»å–ç¬¬ä¸€å¼ å›¾åƒç¡®å®šå°ºå¯¸
        first_img = cv2.imread(str(image_files[0]))
        if first_img is None:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_files[0]}ï¼Œè·³è¿‡episode {episode_idx}")
            continue
        
        height, width = first_img.shape[:2]
        
        # å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡è·å–å›¾åƒå°ºå¯¸ï¼Œè®°å½•ä¸‹æ¥
        if image_shape is None:
            image_shape = [3, height, width]  # RGB, é«˜åº¦, å®½åº¦
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ - ä½¿ç”¨H.264ç¼–ç ä»¥è·å¾—æ›´å¥½çš„å…¼å®¹æ€§
        if code_type=='h264':
            fourcc = cv2.VideoWriter_fourcc(*'avc1') 
        elif code_type=='mp4v':
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    
        video_writer = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
        
        try:
            # æŒ‰é¡ºåºå†™å…¥å›¾åƒï¼Œç¡®ä¿è§†é¢‘å¸§ç´¢å¼•ä¸åŸå§‹frame_idxå¯¹åº”
            # ç¬¬frame_idxå¼ å›¾åƒ â†’ è§†é¢‘ç¬¬frame_idxå¸§ â†’ timestamp = frame_idx/fps
            for img_path in image_files:
                img = cv2.imread(str(img_path))
                if img is not None:
                    video_writer.write(img)
                else:
                    print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {img_path}")
            
            print(f"åˆ›å»ºè§†é¢‘: {video_path}")
        finally:
            video_writer.release()
    
    return image_shape

def create_parquet_files(episode_data: List[Dict], output_data_dir: Path, videos_dir: Path):
    """åˆ›å»ºParquetæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºParquetæ•°æ®æ–‡ä»¶...")
    
    data_output_dir = output_data_dir / "chunk-000"
    data_output_dir.mkdir(parents=True, exist_ok=True)
    
    all_frames = []
    global_index = 0
    
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        
        for frame in ep_data["frames"]:
            frame_data = frame.copy()
            frame_data["index"] = global_index
            
            # åˆ é™¤å›¾åƒè·¯å¾„å­—æ®µï¼Œå› ä¸ºparquetä¸­ä¸å­˜å‚¨å›¾åƒè·¯å¾„
            if "image_path" in frame_data:
                del frame_data["image_path"]  # åˆ é™¤ä¸´æ—¶å­—æ®µ
            
            all_frames.append(frame_data)
            global_index += 1
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜æ¯ä¸ªepisode
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        
        # ç­›é€‰è¯¥episodeçš„frames
        episode_frames = [f for f in all_frames if f["episode_index"] == episode_idx]
        
        if episode_frames:
            df = pd.DataFrame(episode_frames)
            parquet_path = data_output_dir / f"episode_{episode_idx:06d}.parquet"
            df.to_parquet(parquet_path, index=False)
            print(f"ä¿å­˜æ•°æ®æ–‡ä»¶: {parquet_path}")

def create_metadata_files(episode_data: List[Dict], output_dir: Path, dataset_name: str, robot_type: str, fps: float, image_shape=None, code_type: str='h264'):
    """åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶...")
    
    meta_dir = output_dir / "meta"
    meta_dir.mkdir(parents=True, exist_ok=True)
    
    total_episodes = len(episode_data)
    total_frames = sum(ep["length"] for ep in episode_data)
    
    # ä»ç¬¬ä¸€ä¸ªepisodeè·å–æ•°æ®ç»´åº¦ä¿¡æ¯
    if episode_data:
        first_frame = episode_data[0]["frames"][0]
        state_dim = len(first_frame.get("observation.state", []))
        action_dim = len(first_frame.get("action", []))
    else:
        state_dim = action_dim = 7  # é»˜è®¤å€¼
    
    # è®¾ç½®å›¾åƒå½¢çŠ¶ï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if image_shape is None:
        image_shape = [3, 480, 640]  # é»˜è®¤å½¢çŠ¶ï¼šRGB, é«˜åº¦, å®½åº¦
    
    # æ”¶é›†ä»»åŠ¡æ•°é‡
    unique_tasks = set()
    for ep_data in episode_data:
        task_info = ep_data.get("task_info", {})
        task_description = task_info.get("goal", f"{dataset_name}_task")
        unique_tasks.add(task_description)
    
    # åˆ›å»ºinfo.json - åŸºäºNVIDIA Isaac GR00Tå®˜æ–¹æ ¼å¼
    # è°ƒæ•´å›¾åƒshapeä¸º[height, width, channel]æ ¼å¼
    if image_shape:
        video_shape = [image_shape[1], image_shape[2], image_shape[0]]  # [height, width, channel]
    else:
        video_shape = [480, 640, 3]
    
    info = {
        "codebase_version": "v2.0",
        "robot_type": robot_type,
        "total_episodes": total_episodes,
        "total_frames": total_frames,
        "total_tasks": len(unique_tasks),
        "total_videos": 1,  # æˆ‘ä»¬åªæœ‰ä¸€ä¸ªè§†é¢‘æµ
        "total_chunks": 1,  # ä½¿ç”¨å•ä¸ªchunk
        "chunks_size": 1000,
        "fps": fps,
        "splits": {"train": f"0:{total_episodes}"},
        "data_path": "data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet",
        "video_path": "videos/chunk-{episode_chunk:03d}/{video_key}/episode_{episode_index:06d}.mp4",
        "features": {
            "observation.images.ego_view": {
                "dtype": "video",
                "shape": video_shape,
                "names": ["height", "width", "channel"],
                "video_info": {
                    "video.fps": fps,
                    "video.codec": code_type,
                    "video.pix_fmt": "yuv420p",
                    "video.is_depth_map": False,
                    "has_audio": False
                }
            },
            "observation.state": {
                "dtype": "float64",
                "shape": [state_dim],
                "names": [f"motor_{i}" for i in range(state_dim)]
            },
            "action": {
                "dtype": "float64", 
                "shape": [action_dim],
                "names": [f"motor_{i}" for i in range(action_dim)]
            },
            "timestamp": {
                "dtype": "float64",
                "shape": [1]
            },
            "annotation.human.action.task_description": {
                "dtype": "int64",
                "shape": [1]
            },
            "task_index": {
                "dtype": "int64",
                "shape": [1]
            },
            "annotation.human.validity": {
                "dtype": "int64",
                "shape": [1]
            },
            "episode_index": {
                "dtype": "int64",
                "shape": [1]
            },
            "index": {
                "dtype": "int64",
                "shape": [1]
            },
            "next.reward": {
                "dtype": "float64",
                "shape": [1]
            },
            "next.done": {
                "dtype": "bool",
                "shape": [1]
            }
        }
    }
    
    with open(meta_dir / "info.json", "w") as f:
        json.dump(info, f, indent=2)
    
    # åˆ›å»ºmodality.json
    modality = {
        "state": {
            "left_arm": {
                "start": 0,
                "end": 7
            },
            "right_arm": {
                "start": 7,
                "end": 14
            },
            "left_hand": {
                "start": 14,
                "end": 21
            },
            "right_hand": {
                "start": 21,
                "end": 28
            },
            "left_leg": {
                "start": 28,
                "end": 34
            },
            "right_leg": {
                "start": 34,
                "end": 40
            }
        },
        "action": {
            "left_arm": {
                "start": 0,
                "end": 7
            },
            "right_arm": {
                "start": 7,
                "end": 14
            },
            "left_hand": {
                "start": 14,
                "end": 21
            },
            "right_hand": {
                "start": 21,
                "end": 28
            },
            "base_motion": {
                "start": 28,
                "end": 32
            }
        },
        "video": {
            "ego_view": {
                "original_key": "observation.images.ego_view"
            }
        },
        "annotation": {
            "human.action.task_description": {},
            "human.validity": {}
        }
    }
    
    with open(meta_dir / "modality.json", "w") as f:
        json.dump(modality, f, indent=4)
    
    # åˆ›å»ºepisodes.jsonl
    with open(meta_dir / "episodes.jsonl", "w") as f:
        for ep_data in episode_data:
            # è·å–ä»»åŠ¡æè¿°
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            
            episode_info = {
                "episode_index": ep_data["episode_index"],
                "length": ep_data["length"],
                "tasks": [task_description]
            }
            f.write(json.dumps(episode_info) + "\n")
    
    # åˆ›å»ºtasks.jsonl  
    with open(meta_dir / "tasks.jsonl", "w") as f:
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ä»»åŠ¡
        unique_tasks = set()
        for ep_data in episode_data:
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            unique_tasks.add(task_description)
        
        for idx, task in enumerate(unique_tasks):
            task_info = {
                "task_index": idx,
                "task": task
            }
            f.write(json.dumps(task_info) + "\n")
    
    # è®¡ç®—çœŸå®çš„episodeç»Ÿè®¡
    with open(meta_dir / "episodes_stats.jsonl", "w") as f:
        for ep_data in episode_data:
            episode_idx = ep_data["episode_index"]
            frames = ep_data["frames"]
            
            # æå–observation.stateå’Œactionæ•°æ®
            obs_states = []
            actions = []
            
            for frame in frames:
                if "observation.state" in frame and frame["observation.state"] is not None:
                    obs_state = frame["observation.state"]
                    # å¦‚æœæ˜¯æ•°ç»„ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    if isinstance(obs_state, np.ndarray):
                        obs_states.append(obs_state.tolist())
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–qpos
                    elif isinstance(obs_state, dict) and "qpos" in obs_state:
                        obs_states.append(obs_state["qpos"])
                    elif isinstance(obs_state, list):
                        obs_states.append(obs_state)
                if "action" in frame and frame["action"] is not None:
                    action = frame["action"]
                    # å¦‚æœæ˜¯æ•°ç»„ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    if isinstance(action, np.ndarray):
                        actions.append(action.tolist())
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–qpos
                    elif isinstance(action, dict) and "qpos" in action:
                        actions.append(action["qpos"])
                    elif isinstance(action, list):
                        actions.append(action)
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            stats = {
                "episode_index": episode_idx,
                "stats": {}
            }
            
            # è®¡ç®—observation.stateç»Ÿè®¡
            if obs_states:
                # ç¡®ä¿obs_statesæ˜¯ä¸€ä¸ªæ•°å€¼æ•°ç»„
                valid_obs_states = []
                for obs in obs_states:
                    if obs and isinstance(obs, list) and len(obs) > 0:
                        # ç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                        numeric_obs = [float(x) for x in obs if isinstance(x, (int, float))]
                        if numeric_obs:
                            valid_obs_states.append(numeric_obs)
                
                if valid_obs_states:
                    obs_array = np.array(valid_obs_states, dtype=np.float64)
                    stats["stats"]["observation.state"] = {
                        "max": obs_array.max(axis=0).tolist(),
                        "min": obs_array.min(axis=0).tolist(),
                        "mean": obs_array.mean(axis=0).tolist(),
                        "std": obs_array.std(axis=0).tolist()
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    stats["stats"]["observation.state"] = {
                        "max": [0.0] * state_dim,
                        "min": [0.0] * state_dim,
                        "mean": [0.0] * state_dim,
                        "std": [0.0] * state_dim
                    }
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                stats["stats"]["observation.state"] = {
                    "max": [0.0] * state_dim,
                    "min": [0.0] * state_dim,
                    "mean": [0.0] * state_dim,
                    "std": [0.0] * state_dim
                }
            
            # è®¡ç®—actionç»Ÿè®¡
            if actions:
                # ç¡®ä¿actionsæ˜¯ä¸€ä¸ªæ•°å€¼æ•°ç»„
                valid_actions = []
                for action in actions:
                    if action and isinstance(action, list) and len(action) > 0:
                        # ç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                        numeric_action = [float(x) for x in action if isinstance(x, (int, float))]
                        if numeric_action:
                            valid_actions.append(numeric_action)
                
                if valid_actions:
                    action_array = np.array(valid_actions, dtype=np.float64)
                    stats["stats"]["action"] = {
                        "max": action_array.max(axis=0).tolist(),
                        "min": action_array.min(axis=0).tolist(),
                        "mean": action_array.mean(axis=0).tolist(),
                        "std": action_array.std(axis=0).tolist()
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    stats["stats"]["action"] = {
                        "max": [0.0] * action_dim,
                        "min": [0.0] * action_dim,
                        "mean": [0.0] * action_dim,
                        "std": [0.0] * action_dim
                    }
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                stats["stats"]["action"] = {
                    "max": [0.0] * action_dim,
                    "min": [0.0] * action_dim,
                    "mean": [0.0] * action_dim,
                    "std": [0.0] * action_dim
                }
            
            f.write(json.dumps(stats) + "\n")
    
    print("å…ƒæ•°æ®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def main():
    parser = argparse.ArgumentParser(description="å°†OpenWBCæ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼")
    parser.add_argument("--input_dir", type=str, required=True, help="è¾“å…¥æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output_dir", type=str, required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--dataset_name", type=str, required=True, help="æ•°æ®é›†åç§°")
    parser.add_argument("--robot_type", type=str, default="g1", help="æœºå™¨äººç±»å‹")
    parser.add_argument("--fps", type=float, default=30.0, help="è§†é¢‘å¸§ç‡")
    parser.add_argument("--video_enc", type=str, default='h264', help="è§†é¢‘ç¼–ç æ ¼å¼, æ”¯æŒh264æˆ–mp4v")
    parser.add_argument("--filter_file", type=str, default="filter.txt", help="åŒ…å«å…è®¸çš„episodeç¼–å·åˆ—è¡¨çš„æ–‡ä»¶å (ç›¸å¯¹äºinput_dir)")
    
    args = parser.parse_args()
    
    input_dir = Path(args.input_dir)
    output_dir = Path(args.output_dir)
    print('video:', args.video_enc)
    if not input_dir.exists():
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    filter_file_path = input_dir / args.filter_file
    filter_episode_numbers = None
    if filter_file_path.exists():
        try:
            with open(filter_file_path, 'r', encoding='utf-8') as f_filter:
                file_content = f_filter.read().strip()
                filter_episode_numbers = ast.literal_eval(file_content)
                if not isinstance(filter_episode_numbers, list) or not all(isinstance(n, int) for n in filter_episode_numbers):
                    print(f"è­¦å‘Š: {filter_file_path} å†…å®¹æ ¼å¼ä¸æ­£ç¡®, åº”ä¸ºæ•´æ•°åˆ—è¡¨ã€‚å°†å¤„ç†æ‰€æœ‰episodeã€‚")
                    filter_episode_numbers = None
                else:
                    print(f"ä» {filter_file_path} åŠ è½½äº† {len(filter_episode_numbers)} ä¸ªè¦å¤„ç†çš„episodeç¼–å·ã€‚")
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–æˆ–è§£æ {filter_file_path} å¤±è´¥: {e}ã€‚å°†å¤„ç†æ‰€æœ‰episodeã€‚")
            filter_episode_numbers = None
    else:
        print(f"æç¤º: è¿‡æ»¤æ–‡ä»¶ {filter_file_path} æœªæ‰¾åˆ°ã€‚å°†å°è¯•å¤„ç†æ‰€æœ‰episodeã€‚")

    all_potential_episode_dirs = sorted(
        [d for d in input_dir.iterdir() if d.is_dir() and d.name.startswith("episode_")]
    )

    episode_dirs_to_process = []
    if filter_episode_numbers is not None:
        for ep_dir in all_potential_episode_dirs:
            try:
                # Assuming episode name is like "episode_01" or "episode_1"
                ep_num_str = ep_dir.name.split('_')[-1]
                ep_num = int(ep_num_str)
                if ep_num in filter_episode_numbers:
                    episode_dirs_to_process.append(ep_dir)
            except ValueError:
                print(f"è­¦å‘Š: æ— æ³•ä»ç›®å½•å {ep_dir.name} è§£æepisodeç¼–å·ã€‚")
        print(f"æ ¹æ®è¿‡æ»¤æ–‡ä»¶ï¼Œå°†å¤„ç† {len(episode_dirs_to_process)} ä¸ªepisodesã€‚")
    else:
        episode_dirs_to_process = all_potential_episode_dirs
        print(f"å°†å¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„ {len(episode_dirs_to_process)} ä¸ªepisodesã€‚")

    if not episode_dirs_to_process:
        print(f"é”™è¯¯: åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ¡ä»¶çš„episodeç›®å½•è¿›è¡Œå¤„ç†ã€‚")
        return
    
    # é¦–å…ˆæ”¶é›†æ‰€æœ‰ä»»åŠ¡ä¿¡æ¯ä»¥åˆ›å»ºtask_map
    print("åˆ†æä»»åŠ¡ä¿¡æ¯...")
    unique_tasks = set()
    for episode_dir in episode_dirs_to_process:
        data_json = episode_dir / "data.json"
        if data_json.exists():
            try:
                episode_data_raw = parse_json_data(data_json)
                task_info = episode_data_raw.get("text", {})
                task_description = task_info.get("goal", "default_task")
                unique_tasks.add(task_description)
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å–episode {episode_dir} çš„ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
                unique_tasks.add("default_task")
    
    # åˆ›å»ºtask_map
    task_map = {task: idx for idx, task in enumerate(sorted(unique_tasks))}
    print(f"å‘ç° {len(task_map)} ä¸ªä¸åŒçš„ä»»åŠ¡")
    
    # è½¬æ¢æ¯ä¸ªepisode
    episode_data = []
    for i, episode_dir in enumerate(episode_dirs_to_process):
        try:
            ep_data = convert_episode(episode_dir, i, output_dir, args.fps, task_map)
            episode_data.append(ep_data)
        except Exception as e:
            print(f"é”™è¯¯: è½¬æ¢episode {episode_dir} å¤±è´¥: {e}")
            continue
    
    if not episode_data:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•episode")
        return
    
    # åˆ›å»ºè§†é¢‘æ–‡ä»¶
    videos_dir = output_dir / "videos"
    image_shape = create_videos_from_images(input_dir, videos_dir, episode_data, args.fps, code_type=args.video_enc)

    
    # åˆ›å»ºParquetæ•°æ®æ–‡ä»¶  
    data_dir = output_dir / "data"
    create_parquet_files(episode_data, data_dir, videos_dir)
    
    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    create_metadata_files(episode_data, output_dir, args.dataset_name, args.robot_type, args.fps, image_shape, code_type=args.video_enc)
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š è½¬æ¢äº† {len(episode_data)} ä¸ªepisodes")
    print(f"ğŸ¬ æ€»å¸§æ•°: {sum(ep['length'] for ep in episode_data)}")
    
    print(f"\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print(f"from lerobot.common.datasets.lerobot_dataset import LeRobotDataset")
    print(f"dataset = LeRobotDataset('{output_dir}')")
    print(f"print(f'æ•°æ®é›†å¤§å°: {{len(dataset)}}')")

if __name__ == "__main__":
    main() 