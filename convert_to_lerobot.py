#!/usr/bin/env python3
"""
å°†OpenWBCæ ¼å¼çš„æ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼

ç”¨æ³•:
python convert_to_lerobot.py \
    --input_dir /Users/jimmyp/Documents/project/OpenWBC/pick_cola \
    --output_dir ./lerobot_dataset \
    --dataset_name "pick_cola" \
    --robot_type "g1" \
    --fps 30
"""

import argparse
import json
import os
from pathlib import Path
import shutil
import tempfile
from typing import Dict, List, Any
import numpy as np
import pandas as pd
from PIL import Image
import cv2
from tqdm import tqdm

def parse_json_data(json_file: Path) -> Dict[str, Any]:
    """è§£ædata.jsonæ–‡ä»¶"""
    print(f"è§£ææ–‡ä»¶: {json_file}")
    with open(json_file, 'r') as f:
        data = json.load(f)
    return data

def extract_state_vector(states_dict):
    """ä»stateså­—å…¸ä¸­æå–40ç»´çŠ¶æ€å‘é‡"""
    # æŒ‰é¡ºåºæå–: left_arm(7) + right_arm(7) + left_hand(7) + right_hand(7) + left_leg(6) + right_leg(6)
    state_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in states_dict and 'qpos' in states_dict['left_arm']:
        state_parts.extend(states_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)  
    if 'right_arm' in states_dict and 'qpos' in states_dict['right_arm']:
        state_parts.extend(states_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in states_dict and 'qpos' in states_dict['left_hand']:
        state_parts.extend(states_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in states_dict and 'qpos' in states_dict['right_hand']:
        state_parts.extend(states_dict['right_hand']['qpos'])
    
    # left_leg qpos (6ç»´)
    if 'left_leg' in states_dict and 'qpos' in states_dict['left_leg']:
        state_parts.extend(states_dict['left_leg']['qpos'])
    
    # right_leg qpos (6ç»´)
    if 'right_leg' in states_dict and 'qpos' in states_dict['right_leg']:
        state_parts.extend(states_dict['right_leg']['qpos'])
    
    return np.array(state_parts, dtype=np.float32)

def extract_action_vector(actions_dict):
    """ä»actionså­—å…¸ä¸­æå–32ç»´åŠ¨ä½œå‘é‡"""
    # æŒ‰é¡ºåºæå–: left_arm(7) + right_arm(7) + left_hand(7) + right_hand(7) + controller_command(4)
    action_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in actions_dict and 'qpos' in actions_dict['left_arm']:
        action_parts.extend(actions_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)
    if 'right_arm' in actions_dict and 'qpos' in actions_dict['right_arm']:
        action_parts.extend(actions_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in actions_dict and 'qpos' in actions_dict['left_hand']:
        action_parts.extend(actions_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in actions_dict and 'qpos' in actions_dict['right_hand']:
        action_parts.extend(actions_dict['right_hand']['qpos'])
    
    # controller command (4ç»´) - ä½¿ç”¨left_legçš„qpos (å› ä¸ºleft_legå’Œright_legæ˜¯ç›¸åŒçš„é¥æ§å™¨command)
    if 'left_leg' in actions_dict and 'qpos' in actions_dict['left_leg']:
        # è¿™é‡Œqposå¯èƒ½æ˜¯åµŒå¥—åˆ—è¡¨ [[x,y,yaw,z]]ï¼Œéœ€è¦å±•å¹³
        controller_cmd = actions_dict['left_leg']['qpos']
        if isinstance(controller_cmd[0], list):
            controller_cmd = controller_cmd[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
        action_parts.extend(controller_cmd)
    
    return np.array(action_parts, dtype=np.float32)

def convert_episode(input_episode_dir: Path, episode_idx: int, output_dir: Path, fps: float, task_map: Dict[str, int] = None) -> Dict[str, Any]:
    """è½¬æ¢å•ä¸ªepisode"""
    print(f"è½¬æ¢episode {episode_idx}...")
    
    # è¯»å–JSONæ•°æ®
    json_path = input_episode_dir / "data.json"
    if not json_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°data.jsonæ–‡ä»¶: {json_path}")
    
    episode_data = parse_json_data(json_path)
    
    # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
    if "data" not in episode_data:
        raise ValueError(f"Episode {episode_idx}: data.jsonç¼ºå°‘dataå­—æ®µ")
    
    data_frames = episode_data["data"]
    task_info = episode_data.get("text", {})
    
    # åˆ›å»ºepisodeæ•°æ®
    episode_length = len(data_frames)
    frames_data = []
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    colors_dir = input_episode_dir / "colors"
    if colors_dir.exists():
        color_files = sorted([f for f in colors_dir.glob("*.jpg") if f.is_file()])
    else:
        color_files = []
    
    for frame_idx, frame_data in enumerate(data_frames):
        # ç¡®å®štask_index
        task_description = task_info.get("goal", "default_task") if task_info else "default_task"
        current_task_index = task_map.get(task_description, 0) if task_map else 0
        
        processed_frame = {
            "episode_index": episode_idx,
            "timestamp": frame_idx / fps,  # æ—¶é—´æˆ³å¿…é¡»ä¸è§†é¢‘å¸§ç²¾ç¡®å¯¹åº”ï¼šç¬¬frame_idxå¸§ = frame_idx/fpsç§’
            "task_index": current_task_index,
        }
        
        # æ·»åŠ statesæ•°æ®ä½œä¸ºobservation.state
        if "states" in frame_data and frame_data["states"]:
            # æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼Œè¿™é‡Œå‡è®¾statesæ˜¯ä¸ªå­—å…¸æˆ–åˆ—è¡¨
            states = frame_data["states"]
            if isinstance(states, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–left_armçš„æ•°æ®
                if "left_arm" in states:
                    processed_frame["observation.state"] = extract_state_vector(states)
                else:
                    # è½¬æ¢ä¸ºåˆ—è¡¨
                    processed_frame["observation.state"] = extract_state_vector(states)
            else:
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨
                processed_frame["observation.state"] = extract_state_vector(states)
        
        # æ·»åŠ å›¾åƒè·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if frame_idx < len(color_files):
            # è¿™é‡Œæˆ‘ä»¬å…ˆè®°å½•åŸå§‹å›¾åƒè·¯å¾„ï¼Œç¨åä¼šè½¬æ¢ä¸ºè§†é¢‘
            processed_frame["image_path"] = str(color_files[frame_idx])
        
        # æ·»åŠ actionæ•°æ®
        if "actions" in frame_data and frame_data["actions"]:
            actions = frame_data["actions"]
            if isinstance(actions, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–left_armçš„æ•°æ®
                if "left_arm" in actions:
                    processed_frame["action"] = extract_action_vector(actions)
                else:
                    # è½¬æ¢ä¸ºåˆ—è¡¨
                    processed_frame["action"] = extract_action_vector(actions)
            else:
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨
                processed_frame["action"] = extract_action_vector(actions)
        
        # æ·»åŠ episodeç»“æŸæ ‡å¿—å’Œnext.reward
        processed_frame["next.done"] = frame_idx == episode_length - 1
        processed_frame["next.reward"] = 0.0  # æ·»åŠ é»˜è®¤reward
        
        # ä¸ºäº†å…¼å®¹GR00Tæ ¼å¼ï¼Œæ·»åŠ ä»»åŠ¡æè¿°ç›¸å…³å­—æ®µ
        if task_info and "goal" in task_info:
            processed_frame["annotation.human.action.task_description"] = task_info["goal"]
        
        # æ·»åŠ annotation validityå­—æ®µï¼Œè¡¨ç¤ºäººå·¥æ ‡æ³¨çš„æœ‰æ•ˆæ€§
        processed_frame["annotation.human.validity"] = 1
        
        frames_data.append(processed_frame)
    
    return {
        "frames": frames_data,
        "length": episode_length,
        "episode_index": episode_idx,
        "task_info": task_info
    }

def create_videos_from_images(input_dir: Path, output_videos_dir: Path, episode_data: List[Dict], fps: float):
    """ä»å›¾åƒåºåˆ—åˆ›å»ºè§†é¢‘æ–‡ä»¶"""
    print("åˆ›å»ºè§†é¢‘æ–‡ä»¶...")
    
    # ä¸ºæ¯ä¸ªepisodeåˆ›å»ºè§†é¢‘
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        episode_dir = input_dir / f"episode_{episode_idx+1:04d}"  # episodeç›®å½•ä»1å¼€å§‹ç¼–å·
        colors_dir = episode_dir / "colors"
        
        if not colors_dir.exists():
            print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰colorsç›®å½•ï¼Œè·³è¿‡è§†é¢‘åˆ›å»º")
            continue
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = sorted([f for f in colors_dir.glob("*.jpg") if f.is_file()])
        if not image_files:
            print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰å›¾åƒæ–‡ä»¶ï¼Œè·³è¿‡è§†é¢‘åˆ›å»º")
            continue
        
        # ç¡®å®šè§†é¢‘è¾“å‡ºè·¯å¾„
        video_output_dir = output_videos_dir / "chunk-000" / "observation.images.main"
        video_output_dir.mkdir(parents=True, exist_ok=True)
        video_path = video_output_dir / f"episode_{episode_idx:06d}.mp4"
        
        # è¯»å–ç¬¬ä¸€å¼ å›¾åƒç¡®å®šå°ºå¯¸
        first_img = cv2.imread(str(image_files[0]))
        if first_img is None:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_files[0]}ï¼Œè·³è¿‡episode {episode_idx}")
            continue
        
        height, width = first_img.shape[:2]
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ - ä½¿ç”¨H.264ç¼–ç ä»¥è·å¾—æ›´å¥½çš„å…¼å®¹æ€§
        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264ç¼–ç ï¼Œæ›´å…¼å®¹
        video_writer = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
        
        try:
            # æŒ‰é¡ºåºå†™å…¥å›¾åƒï¼Œç¡®ä¿è§†é¢‘å¸§ç´¢å¼•ä¸åŸå§‹frame_idxå¯¹åº”
            # ç¬¬frame_idxå¼ å›¾åƒ â†’ è§†é¢‘ç¬¬frame_idxå¸§ â†’ timestamp = frame_idx/fps
            for img_path in image_files:
                img = cv2.imread(str(img_path))
                if img is not None:
                    video_writer.write(img)
                else:
                    print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {img_path}")
            
            print(f"åˆ›å»ºè§†é¢‘: {video_path}")
        finally:
            video_writer.release()

def create_parquet_files(episode_data: List[Dict], output_data_dir: Path, videos_dir: Path):
    """åˆ›å»ºParquetæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºParquetæ•°æ®æ–‡ä»¶...")
    
    data_output_dir = output_data_dir / "chunk-000"
    data_output_dir.mkdir(parents=True, exist_ok=True)
    
    all_frames = []
    global_index = 0
    
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        
        for frame in ep_data["frames"]:
            frame_data = frame.copy()
            frame_data["index"] = global_index
            
            # åˆ é™¤å›¾åƒè·¯å¾„å­—æ®µï¼Œå› ä¸ºparquetä¸­ä¸å­˜å‚¨å›¾åƒè·¯å¾„
            if "image_path" in frame_data:
                del frame_data["image_path"]  # åˆ é™¤ä¸´æ—¶å­—æ®µ
            
            all_frames.append(frame_data)
            global_index += 1
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜æ¯ä¸ªepisode
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        
        # ç­›é€‰è¯¥episodeçš„frames
        episode_frames = [f for f in all_frames if f["episode_index"] == episode_idx]
        
        if episode_frames:
            df = pd.DataFrame(episode_frames)
            parquet_path = data_output_dir / f"episode_{episode_idx:06d}.parquet"
            df.to_parquet(parquet_path, index=False)
            print(f"ä¿å­˜æ•°æ®æ–‡ä»¶: {parquet_path}")

def create_metadata_files(episode_data: List[Dict], output_dir: Path, dataset_name: str, robot_type: str, fps: float):
    """åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶...")
    
    meta_dir = output_dir / "meta"
    meta_dir.mkdir(parents=True, exist_ok=True)
    
    total_episodes = len(episode_data)
    total_frames = sum(ep["length"] for ep in episode_data)
    
    # ä»ç¬¬ä¸€ä¸ªepisodeè·å–æ•°æ®ç»´åº¦ä¿¡æ¯
    if episode_data:
        first_frame = episode_data[0]["frames"][0]
        state_dim = len(first_frame.get("observation.state", []))
        action_dim = len(first_frame.get("action", []))
    else:
        state_dim = action_dim = 7  # é»˜è®¤å€¼
    
    # åˆ›å»ºinfo.json
    info = {
        "codebase_version": "v2.1",
        "robot_type": robot_type,
        "total_episodes": total_episodes,
        "total_frames": total_frames,
        "fps": fps,
        "splits": {"train": f"0:{total_episodes}"},
        "data_path": "data/chunk-000/episode_{episode_index:06d}.parquet",
        "video_path": "videos/chunk-000/{camera_key}/episode_{episode_index:06d}.mp4",
        "features": {
            "observation.state": {
                "dtype": "float32",
                "shape": [state_dim],
                "names": [f"joint{i}" for i in range(state_dim)]
            },
            "action": {
                "dtype": "float32", 
                "shape": [action_dim],
                "names": [f"action{i}" for i in range(action_dim)]
            },
            "episode_index": {"dtype": "int64"},
            "timestamp": {"dtype": "float32"},
            "task_index": {"dtype": "int64"},
            "next.done": {"dtype": "bool"},
            "next.reward": {"dtype": "float32"},
            "annotation.human.action.task_description": {"dtype": "string"},
            "annotation.human.validity": {"dtype": "int64"},
            "index": {"dtype": "int64"}
        }
    }
    
    with open(meta_dir / "info.json", "w") as f:
        json.dump(info, f, indent=2)
    
    # åˆ›å»ºepisodes.jsonl
    with open(meta_dir / "episodes.jsonl", "w") as f:
        for ep_data in episode_data:
            # è·å–ä»»åŠ¡æè¿°
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            
            episode_info = {
                "episode_index": ep_data["episode_index"],
                "length": ep_data["length"],
                "tasks": [task_description]
            }
            f.write(json.dumps(episode_info) + "\n")
    
    # åˆ›å»ºtasks.jsonl  
    with open(meta_dir / "tasks.jsonl", "w") as f:
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ä»»åŠ¡
        unique_tasks = set()
        for ep_data in episode_data:
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            unique_tasks.add(task_description)
        
        for idx, task in enumerate(unique_tasks):
            task_info = {
                "task_index": idx,
                "task": task
            }
            f.write(json.dumps(task_info) + "\n")
    
    # è®¡ç®—çœŸå®çš„episodeç»Ÿè®¡
    with open(meta_dir / "episodes_stats.jsonl", "w") as f:
        for ep_data in episode_data:
            episode_idx = ep_data["episode_index"]
            frames = ep_data["frames"]
            
            # æå–observation.stateå’Œactionæ•°æ®
            obs_states = []
            actions = []
            
            for frame in frames:
                if "observation.state" in frame and frame["observation.state"] is not None:
                    obs_state = frame["observation.state"]
                    # å¦‚æœæ˜¯æ•°ç»„ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    if isinstance(obs_state, np.ndarray):
                        obs_states.append(obs_state.tolist())
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–qpos
                    elif isinstance(obs_state, dict) and "qpos" in obs_state:
                        obs_states.append(obs_state["qpos"])
                    elif isinstance(obs_state, list):
                        obs_states.append(obs_state)
                if "action" in frame and frame["action"] is not None:
                    action = frame["action"]
                    # å¦‚æœæ˜¯æ•°ç»„ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    if isinstance(action, np.ndarray):
                        actions.append(action.tolist())
                    # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–qpos
                    elif isinstance(action, dict) and "qpos" in action:
                        actions.append(action["qpos"])
                    elif isinstance(action, list):
                        actions.append(action)
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            stats = {
                "episode_index": episode_idx,
                "stats": {}
            }
            
            # è®¡ç®—observation.stateç»Ÿè®¡
            if obs_states:
                # ç¡®ä¿obs_statesæ˜¯ä¸€ä¸ªæ•°å€¼æ•°ç»„
                valid_obs_states = []
                for obs in obs_states:
                    if obs and isinstance(obs, list) and len(obs) > 0:
                        # ç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                        numeric_obs = [float(x) for x in obs if isinstance(x, (int, float))]
                        if numeric_obs:
                            valid_obs_states.append(numeric_obs)
                
                if valid_obs_states:
                    obs_array = np.array(valid_obs_states, dtype=np.float32)
                    stats["stats"]["observation.state"] = {
                        "max": obs_array.max(axis=0).tolist(),
                        "min": obs_array.min(axis=0).tolist(),
                        "mean": obs_array.mean(axis=0).tolist(),
                        "std": obs_array.std(axis=0).tolist()
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    stats["stats"]["observation.state"] = {
                        "max": [0.0] * state_dim,
                        "min": [0.0] * state_dim,
                        "mean": [0.0] * state_dim,
                        "std": [0.0] * state_dim
                    }
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                stats["stats"]["observation.state"] = {
                    "max": [0.0] * state_dim,
                    "min": [0.0] * state_dim,
                    "mean": [0.0] * state_dim,
                    "std": [0.0] * state_dim
                }
            
            # è®¡ç®—actionç»Ÿè®¡
            if actions:
                # ç¡®ä¿actionsæ˜¯ä¸€ä¸ªæ•°å€¼æ•°ç»„
                valid_actions = []
                for action in actions:
                    if action and isinstance(action, list) and len(action) > 0:
                        # ç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                        numeric_action = [float(x) for x in action if isinstance(x, (int, float))]
                        if numeric_action:
                            valid_actions.append(numeric_action)
                
                if valid_actions:
                    action_array = np.array(valid_actions, dtype=np.float32)
                    stats["stats"]["action"] = {
                        "max": action_array.max(axis=0).tolist(),
                        "min": action_array.min(axis=0).tolist(),
                        "mean": action_array.mean(axis=0).tolist(),
                        "std": action_array.std(axis=0).tolist()
                    }
                else:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    stats["stats"]["action"] = {
                        "max": [0.0] * action_dim,
                        "min": [0.0] * action_dim,
                        "mean": [0.0] * action_dim,
                        "std": [0.0] * action_dim
                    }
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                stats["stats"]["action"] = {
                    "max": [0.0] * action_dim,
                    "min": [0.0] * action_dim,
                    "mean": [0.0] * action_dim,
                    "std": [0.0] * action_dim
                }
            
            f.write(json.dumps(stats) + "\n")
    
    print("å…ƒæ•°æ®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def main():
    parser = argparse.ArgumentParser(description="å°†OpenWBCæ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼")
    parser.add_argument("--input_dir", type=str, required=True, help="è¾“å…¥æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output_dir", type=str, required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--dataset_name", type=str, required=True, help="æ•°æ®é›†åç§°")
    parser.add_argument("--robot_type", type=str, default="g1", help="æœºå™¨äººç±»å‹")
    parser.add_argument("--fps", type=float, default=30.0, help="è§†é¢‘å¸§ç‡")
    
    args = parser.parse_args()
    
    input_dir = Path(args.input_dir)
    output_dir = Path(args.output_dir)
    
    if not input_dir.exists():
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰episodeç›®å½•
    episode_dirs = sorted([d for d in input_dir.iterdir() if d.is_dir() and d.name.startswith("episode_")])
    
    if not episode_dirs:
        print(f"é”™è¯¯: åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°episodeç›®å½•")
        return
    
    print(f"æ‰¾åˆ° {len(episode_dirs)} ä¸ªepisodes")
    
    # é¦–å…ˆæ”¶é›†æ‰€æœ‰ä»»åŠ¡ä¿¡æ¯ä»¥åˆ›å»ºtask_map
    print("åˆ†æä»»åŠ¡ä¿¡æ¯...")
    unique_tasks = set()
    for episode_dir in episode_dirs:
        data_json = episode_dir / "data.json"
        if data_json.exists():
            try:
                episode_data_raw = parse_json_data(data_json)
                task_info = episode_data_raw.get("text", {})
                task_description = task_info.get("goal", "default_task")
                unique_tasks.add(task_description)
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å–episode {episode_dir} çš„ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
                unique_tasks.add("default_task")
    
    # åˆ›å»ºtask_map
    task_map = {task: idx for idx, task in enumerate(sorted(unique_tasks))}
    print(f"å‘ç° {len(task_map)} ä¸ªä¸åŒçš„ä»»åŠ¡")
    
    # è½¬æ¢æ¯ä¸ªepisode
    episode_data = []
    for i, episode_dir in enumerate(episode_dirs):
        try:
            ep_data = convert_episode(episode_dir, i, output_dir, args.fps, task_map)
            episode_data.append(ep_data)
        except Exception as e:
            print(f"é”™è¯¯: è½¬æ¢episode {episode_dir} å¤±è´¥: {e}")
            continue
    
    if not episode_data:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•episode")
        return
    
    # åˆ›å»ºè§†é¢‘æ–‡ä»¶
    videos_dir = output_dir / "videos"
    create_videos_from_images(input_dir, videos_dir, episode_data, args.fps)
    
    # åˆ›å»ºParquetæ•°æ®æ–‡ä»¶  
    data_dir = output_dir / "data"
    create_parquet_files(episode_data, data_dir, videos_dir)
    
    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    create_metadata_files(episode_data, output_dir, args.dataset_name, args.robot_type, args.fps)
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š è½¬æ¢äº† {len(episode_data)} ä¸ªepisodes")
    print(f"ğŸ¬ æ€»å¸§æ•°: {sum(ep['length'] for ep in episode_data)}")
    
    print(f"\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print(f"from lerobot.common.datasets.lerobot_dataset import LeRobotDataset")
    print(f"dataset = LeRobotDataset('{output_dir}')")
    print(f"print(f'æ•°æ®é›†å¤§å°: {{len(dataset)}}')")

if __name__ == "__main__":
    main() 